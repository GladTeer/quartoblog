{
  "hash": "4598f20389ff966a757bbb219120ecb5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Ordinal Regression Lab Answers\"\noutput: \n  tufte::tufte_html:\n    css: \n    tufte_variant: \"envisioned\"\n    highlight: github-dark\n    fig_height: 10\n    fig_width: 16\n    toc: true\n    toc_depth: 1\nexecute: \n  message: false\n  warning: false\nformat: \n  html:\n    code-fold: true\n    code-overflow: wrap\nengine: knitr\n---\n\n\n# Lab 3- Ordinal Regression\n\n## Instructions\n\n-   If you are fitting a model, display the model output in a neatly formatted table. (The `tidy` and `kable` functions can help!)\n\n-   If you are creating a plot, use clear labels for all axes, titles, etc.\n\n-   If you are using Github, don't forget to commit and push your work to to it regularly, at least after each exercise. Write short and informative commit messages.\n    Else, if you are submitting on Canvas, make sure that the version you submit is the latest, and that it runs/knits without any errors. \n\n-   When you're done, we should be able to knit the final version of the QMD in your GitHub as a HTML.\n\n# Lab\n\nThe data for this week's lab is taken from the Great British Bake-off (GBBO, https://bakeoff.netlify.app/). In this lab you will be looking at `Gender` and `Age` as a predictor of technical rank. For this exercise, we will only be looking at those who were in top 3 of technical.\n\nIn the GBBO, the bakers are usually provided with a list of ingredients and basic instructions, but they may not have access to specific measurements or details on how to prepare the ingredients. The judges evaluate the bakers' finished products based on factors such as appearance, texture, and flavor, but also compare the bakers' results to a standard version of the recipe that has been prepared in advance by the judges or a baking expert.\n\nThe dataset contains 3 variables:\n\n-   `Gender`: M = MALE, F = FEMALE\n\n-   `Age`: Age of baker\n\n-   `Technical Rank`: Rank in technical (1,2,3)\n\n## Load packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(performance)\nlibrary(ordinal) #clm\nlibrary(car) # anova\nlibrary(ggeffects) #  viz\nlibrary(gofcat) # brant\nlibrary(brms)\nlibrary(emmeans) # contrasts\nlibrary(knitr)\n```\n:::\n\n\n## Load data\n\n-   Make sure only the top 3 ranks are being used. *For some reason, there are missing ranks (my guess is they did not announce rank on TV)*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngbbo <- read_csv(\"https://raw.githubusercontent.com/suyoghc/PSY-504_Spring-2025/refs/heads/main/Ordinal%20Regression/data/GBBO.csv\")\ncolnames(gbbo)[3]= 'Tech_Rank'\n\n# Enter code to filter. Think about the data type that would be relevant for Rank\ngbbo = gbbo%>%\n  filter(!is.na(Tech_Rank))\n```\n:::\n\n\n## Explore\n\n-   Plot two figures showing the percentage of bakers in each rank--- create one for `Gender` and `Age`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Calculate percentages for Gender\n    \ngender_percent <- gbbo %>%\n  group_by(Gender, Tech_Rank) %>%\n  summarise(Count = n(), .groups = 'drop') %>%\n  group_by(Gender) %>%\n  mutate(Percentage = Count / sum(Count) * 100)\n\n# Plot for Gender\nggplot(gender_percent, aes(x = Tech_Rank, y = Percentage, fill = Gender)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  labs(title = \"Percentage of Bakers by Rank and Gender\",\n       x = \"Rank\",\n       y = \"Percentage\",\n       fill = \"Gender\")\n```\n\n::: {.cell-output-display}\n![](ord_lab_q_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate percentages for Age\nAge_percent <- gbbo %>%\n  group_by(Age, Tech_Rank) %>%\n  summarise(Count = n(), .groups = 'drop') %>%\n  group_by(Age) %>%\n  mutate(Percentage = Count / sum(Count) * 100)\n\n# Plot for Gender\nggplot(Age_percent, aes(x = Tech_Rank, y = Percentage, fill = Age)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  labs(title = \"Percentage of Age in every rank\",\n       x = \"Rank\",\n       y = \"Percentage\",\n       fill = \"Age\")\n```\n\n::: {.cell-output-display}\n![](ord_lab_q_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n## Ordinal Analysis\n\n-   If you haven't already, convert the outcome variable to an ordered factor. What does the order here represent?\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    gbbo$Tech_Rank <- factor(gbbo$Tech_Rank, \n                         ordered = TRUE)\n    ```\n    :::\n\n\n-   Convert input variables to categorical factors as appropriate.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    #gbbo$Age <- as.factor(gbbo$Age)\n    gbbo_ori = gbbo\n    gbbo$Gender <- as.factor(gbbo$Gender)\n    ```\n    :::\n\n\n-   Run a ordinal logistic regression model against all relevant input variables. Interpret the effects for `Gender`, `Age` and `Gender*Age` (even if they are non-significant).\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    ordinal_log <- clm(Tech_Rank ~ Gender + Age, data = gbbo)\n    summary(ordinal_log)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    formula: Tech_Rank ~ Gender + Age\n    data:    gbbo\n    \n     link  threshold nobs logLik   AIC     niter max.grad cond.H \n     logit flexible  771  -1813.42 3654.84 6(0)  1.87e-10 2.6e+05\n    \n    Coefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n    GenderM 0.266375   0.127313   2.092   0.0364 * \n    Age     0.016228   0.005142   3.156   0.0016 **\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    \n    Threshold coefficients:\n          Estimate Std. Error z value\n    1|2    -1.1878     0.2187  -5.432\n    2|3    -0.3170     0.2093  -1.515\n    3|4     0.2875     0.2082   1.381\n    4|5     0.7755     0.2096   3.700\n    5|6     1.2114     0.2120   5.714\n    6|7     1.6298     0.2158   7.554\n    7|8     2.0673     0.2214   9.338\n    8|9     2.5213     0.2292  10.999\n    9|10    3.0593     0.2426  12.611\n    10|11   3.7452     0.2695  13.896\n    11|12   4.7216     0.3415  13.828\n    12|13   6.6829     0.7383   9.052\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   Test if the interaction is warranted\n\n#Hint: You need to create two models with clm(); one with interaction and one without.\n#Then you compare them using the anova test using anova()\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n       ordinal_log_int <- clm(Tech_Rank ~ Gender + Age + Gender*Age, data = gbbo_ori)\n       summary(ordinal_log)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    formula: Tech_Rank ~ Gender + Age\n    data:    gbbo\n    \n     link  threshold nobs logLik   AIC     niter max.grad cond.H \n     logit flexible  771  -1813.42 3654.84 6(0)  1.87e-10 2.6e+05\n    \n    Coefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n    GenderM 0.266375   0.127313   2.092   0.0364 * \n    Age     0.016228   0.005142   3.156   0.0016 **\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    \n    Threshold coefficients:\n          Estimate Std. Error z value\n    1|2    -1.1878     0.2187  -5.432\n    2|3    -0.3170     0.2093  -1.515\n    3|4     0.2875     0.2082   1.381\n    4|5     0.7755     0.2096   3.700\n    5|6     1.2114     0.2120   5.714\n    6|7     1.6298     0.2158   7.554\n    7|8     2.0673     0.2214   9.338\n    8|9     2.5213     0.2292  10.999\n    9|10    3.0593     0.2426  12.611\n    10|11   3.7452     0.2695  13.896\n    11|12   4.7216     0.3415  13.828\n    12|13   6.6829     0.7383   9.052\n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n       summary(ordinal_log_int)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    formula: Tech_Rank ~ Gender + Age + Gender * Age\n    data:    gbbo_ori\n    \n     link  threshold nobs logLik   AIC     niter max.grad cond.H \n     logit flexible  771  -1813.41 3656.82 6(0)  1.87e-10 4.2e+05\n    \n    Coefficients:\n                Estimate Std. Error z value Pr(>|z|)  \n    GenderM     0.218602   0.396021   0.552   0.5809  \n    Age         0.015732   0.006450   2.439   0.0147 *\n    GenderM:Age 0.001354   0.010629   0.127   0.8986  \n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    \n    Threshold coefficients:\n          Estimate Std. Error z value\n    1|2    -1.2059     0.2606  -4.627\n    2|3    -0.3350     0.2527  -1.326\n    3|4     0.2693     0.2523   1.068\n    4|5     0.7572     0.2539   2.982\n    5|6     1.1931     0.2561   4.658\n    6|7     1.6114     0.2594   6.212\n    7|8     2.0490     0.2640   7.762\n    8|9     2.5031     0.2702   9.264\n    9|10    3.0412     0.2809  10.826\n    10|11   3.7274     0.3037  12.272\n    11|12   4.7039     0.3689  12.752\n    12|13   6.6651     0.7514   8.870\n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n       nested_comp = anova(ordinal_log,ordinal_log_int)\n       print(nested_comp)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    Likelihood ratio tests of cumulative link models:\n     \n                    formula:                                link: threshold:\n    ordinal_log     Tech_Rank ~ Gender + Age                logit flexible  \n    ordinal_log_int Tech_Rank ~ Gender + Age + Gender * Age logit flexible  \n    \n                    no.par    AIC  logLik LR.stat df Pr(>Chisq)\n    ordinal_log         14 3654.8 -1813.4                      \n    ordinal_log_int     15 3656.8 -1813.4  0.0162  1     0.8986\n    ```\n    \n    \n    :::\n    :::\n\n\n\n-   Use `ggemmeans` to create a figure showing the interaction between `Gender` and `Age` as a function of rank. Plot predicted probabilities from the model.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    prediction = ggemmeans(ordinal_log_int, terms = c('Age','Gender'))\n    print(prediction)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    # Predicted probabilities of Tech_Rank\n    \n    Tech_Rank: 1\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.19 | 0.14, 0.25\n     30 |      0.16 | 0.12, 0.19\n     45 |      0.13 | 0.10, 0.16\n     75 |      0.08 | 0.04, 0.13\n    \n    Tech_Rank: 1\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.16 | 0.10, 0.21\n     30 |      0.13 | 0.10, 0.15\n     45 |      0.10 | 0.07, 0.13\n     75 |      0.06 | 0.02, 0.11\n    \n    Tech_Rank: 2\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.17 | 0.13, 0.21\n     30 |      0.15 | 0.12, 0.18\n     45 |      0.13 | 0.11, 0.16\n     75 |      0.10 | 0.06, 0.14\n    \n    Tech_Rank: 2\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.15 | 0.11, 0.19\n     30 |      0.13 | 0.10, 0.16\n     45 |      0.11 | 0.08, 0.14\n     75 |      0.08 | 0.03, 0.12\n    \n    Tech_Rank: 3\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.15 | 0.12, 0.17\n     30 |      0.14 | 0.12, 0.17\n     45 |      0.13 | 0.11, 0.16\n     75 |      0.11 | 0.07, 0.14\n    \n    Tech_Rank: 3\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.14 | 0.11, 0.17\n     30 |      0.13 | 0.11, 0.16\n     45 |      0.12 | 0.09, 0.14\n     75 |      0.09 | 0.05, 0.13\n    \n    Tech_Rank: 4\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.12 | 0.10, 0.14\n     30 |      0.12 | 0.10, 0.14\n     45 |      0.12 | 0.10, 0.14\n     75 |      0.11 | 0.08, 0.14\n    \n    Tech_Rank: 4\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.12 | 0.10, 0.14\n     30 |      0.12 | 0.10, 0.14\n     45 |      0.11 | 0.09, 0.14\n     75 |      0.10 | 0.06, 0.13\n    \n    Tech_Rank: 5\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.10 | 0.07, 0.12\n     30 |      0.10 | 0.08, 0.12\n     45 |      0.11 | 0.08, 0.13\n     75 |      0.11 | 0.08, 0.13\n    \n    Tech_Rank: 5\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.10 | 0.08, 0.12\n     30 |      0.11 | 0.08, 0.13\n     45 |      0.11 | 0.09, 0.13\n     75 |      0.10 | 0.07, 0.13\n    \n    Tech_Rank: 6\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.08 | 0.06, 0.10\n     30 |      0.08 | 0.07, 0.10\n     45 |      0.09 | 0.07, 0.11\n     75 |      0.10 | 0.08, 0.13\n    \n    Tech_Rank: 6\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.08 | 0.06, 0.11\n     30 |      0.09 | 0.07, 0.11\n     45 |      0.10 | 0.08, 0.12\n     75 |      0.10 | 0.08, 0.13\n    \n    Tech_Rank: 7\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.06 | 0.04, 0.08\n     30 |      0.07 | 0.05, 0.09\n     45 |      0.08 | 0.06, 0.10\n     75 |      0.10 | 0.07, 0.13\n    \n    Tech_Rank: 7\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.07 | 0.05, 0.09\n     30 |      0.08 | 0.06, 0.10\n     45 |      0.09 | 0.07, 0.12\n     75 |      0.11 | 0.08, 0.13\n    \n    Tech_Rank: 8\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.05 | 0.03, 0.06\n     30 |      0.06 | 0.04, 0.07\n     45 |      0.06 | 0.05, 0.08\n     75 |      0.09 | 0.05, 0.12\n    \n    Tech_Rank: 8\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.06 | 0.03, 0.08\n     30 |      0.07 | 0.05, 0.08\n     45 |      0.08 | 0.05, 0.10\n     75 |      0.10 | 0.06, 0.13\n    \n    Tech_Rank: 9\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.04 | 0.02, 0.05\n     30 |      0.04 | 0.03, 0.06\n     45 |      0.05 | 0.04, 0.07\n     75 |      0.08 | 0.04, 0.11\n    \n    Tech_Rank: 9\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.04 | 0.03, 0.06\n     30 |      0.06 | 0.04, 0.07\n     45 |      0.07 | 0.04, 0.09\n     75 |      0.09 | 0.05, 0.14\n    \n    Tech_Rank: 10\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.03 | 0.02, 0.04\n     30 |      0.03 | 0.02, 0.05\n     45 |      0.04 | 0.03, 0.06\n     75 |      0.06 | 0.03, 0.09\n    \n    Tech_Rank: 10\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.03 | 0.02, 0.05\n     30 |      0.04 | 0.03, 0.06\n     45 |      0.05 | 0.03, 0.07\n     75 |      0.08 | 0.03, 0.13\n    \n    Tech_Rank: 11\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.02 | 0.01, 0.03\n     30 |      0.02 | 0.01, 0.03\n     45 |      0.03 | 0.02, 0.04\n     75 |      0.04 | 0.02, 0.07\n    \n    Tech_Rank: 11\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.02 | 0.01, 0.04\n     30 |      0.03 | 0.02, 0.04\n     45 |      0.04 | 0.02, 0.05\n     75 |      0.06 | 0.02, 0.10\n    \n    Tech_Rank: 12\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.01 | 0.00, 0.02\n     30 |      0.01 | 0.01, 0.02\n     45 |      0.02 | 0.01, 0.02\n     75 |      0.02 | 0.01, 0.04\n    \n    Tech_Rank: 12\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.01 | 0.00, 0.02\n     30 |      0.02 | 0.01, 0.03\n     45 |      0.02 | 0.01, 0.03\n     75 |      0.03 | 0.01, 0.06\n    \n    Tech_Rank: 13\n    Gender: F\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.00 | 0.00, 0.00\n     30 |      0.00 | 0.00, 0.00\n     45 |      0.00 | 0.00, 0.01\n     75 |      0.00 | 0.00, 0.01\n    \n    Tech_Rank: 13\n    Gender: M\n    \n    Age | Predicted |     95% CI\n    ----------------------------\n     15 |      0.00 | 0.00, 0.00\n     30 |      0.00 | 0.00, 0.01\n     45 |      0.00 | 0.00, 0.01\n     75 |      0.01 | 0.00, 0.01\n    ```\n    \n    \n    :::\n    \n    ```{.r .cell-code}\n       ggplot(prediction, aes(x = x, y = predicted, color = group)) +\n    geom_line() +\n    labs(x = \"Age\", y = \"Predicted Probability\", color = \"Gender\") +\n     theme_minimal()\n    ```\n    \n    ::: {.cell-output-display}\n    ![](ord_lab_q_files/figure-html/unnamed-chunk-9-1.png){width=672}\n    :::\n    :::\n\n\n### Latent Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\nols_clm = MASS::polr(Tech_Rank~Gender*Age, data=gbbo)\n\nggeffect(ols_clm, c(\"Age[all]\", \"Gender\"), latent=TRUE) %>% plot()\n```\n\n::: {.cell-output-display}\n![](ord_lab_q_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n-   Use the Brant test to support or reject the hypothesis that the proportional odds assumption holds for your simplified model.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    brant.test(ols_clm)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    \n    ```\n    \n    Brant Test:\n                   chi-sq   df   pr(>chi)  \n    Omnibus          40.1   33      0.184  \n    GenderM          13.9   11      0.240  \n    Age              13.8   11      0.243  \n    GenderM:Age      18.0   11      0.082 .\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    \n    H0: Proportional odds assumption holds\n    ```\n    \n    \n    :::\n    :::\n\n\n    ## `brms`\n\n-   Below is a model implementation using the `brms` package. We will just use the default priors for this. \nThe exercise is to run this code and note your observations. \nWhat are salient differences you observe in how the model fitting takes place\nWith respect to the results, how do you compare the results of the model you fit with `clm` and the one you fit with `brms`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  ols2_brm = brm(Tech_Rank ~  Gender*Age, data=gbbo, family = cumulative, cores = 4,chains = 4)\n```\n:::\n\n\n-  The `conditional_effects` function is used to plot predicted probabilities by Gender and Age across each rank. \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    conditional_effects(ols2_brm, categorical = T)\n    ```\n    \n    ::: {.cell-output-display}\n    ![](ord_lab_q_files/figure-html/unnamed-chunk-13-1.png){width=672}\n    :::\n    \n    ::: {.cell-output-display}\n    ![](ord_lab_q_files/figure-html/unnamed-chunk-13-2.png){width=672}\n    :::\n    :::\n\n\n- `check_predictions` from the `easystats` `performance` package is used for examining model fit (i.e., does the data fit the model being used?). \nRun the below code. What do you think?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_predictions(ols2_brm)\n```\n\n::: {.cell-output-display}\n![](ord_lab_q_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "ord_lab_q_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}